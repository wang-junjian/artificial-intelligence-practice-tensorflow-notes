{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 没有声明为变量(tf.Variable)，导致的错误。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_2:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_3:0' shape=(2, 1) dtype=float32_ref>\"] and loss Tensor(\"Mean_6:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-2a9e1f27ff10>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mtrain_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGradientDescentOptimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mminimize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/training/optimizer.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(self, loss, global_step, var_list, gate_gradients, aggregation_method, colocate_gradients_with_ops, name, grad_loss)\u001b[0m\n\u001b[1;32m    404\u001b[0m           \u001b[0;34m\"No gradients provided for any variable, check your graph for ops\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    405\u001b[0m           \u001b[0;34m\" that do not support gradients, between variables %s and loss %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m           ([str(v) for _, v in grads_and_vars], loss))\n\u001b[0m\u001b[1;32m    407\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m     return self.apply_gradients(grads_and_vars, global_step=global_step,\n",
      "\u001b[0;31mValueError\u001b[0m: No gradients provided for any variable, check your graph for ops that do not support gradients, between variables [\"<tf.Variable 'Variable:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_1:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_2:0' shape=(2, 1) dtype=float32_ref>\", \"<tf.Variable 'Variable_3:0' shape=(2, 1) dtype=float32_ref>\"] and loss Tensor(\"Mean_6:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SEED = 1\n",
    "\n",
    "rdm = np.random.RandomState(SEED)\n",
    "\n",
    "X = rdm.rand(32, 2)\n",
    "Y_ = [[x0+x1] for (x0, x1) in X]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "\n",
    "#没有声明为变量，导致的错误。\n",
    "w1 = tf.random_normal((2,1), stddev=1, seed=1)\n",
    "\n",
    "y = tf.matmul(x, w1)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = i*BATCH_SIZE % 32\n",
    "        end = start+BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y_[start:end]})\n",
    "        \n",
    "        if (i+1) % 500 == 0:\n",
    "            print(i, ' w1: ', sess.run(w1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "499  w1:  [[-0.5362731]\n",
      " [ 1.648221 ]]\n",
      "999  w1:  [[-0.34143615]\n",
      " [ 1.7232993 ]]\n",
      "1499  w1:  [[-0.1968007]\n",
      " [ 1.746618 ]]\n",
      "1999  w1:  [[-0.08417814]\n",
      " [ 1.7402178 ]]\n",
      "2499  w1:  [[0.00749679]\n",
      " [1.7172729 ]]\n",
      "2999  w1:  [[0.08499482]\n",
      " [1.685622  ]]\n",
      "3499  w1:  [[0.1524945]\n",
      " [1.6499013]]\n",
      "3999  w1:  [[0.21260695]\n",
      " [1.6128254 ]]\n",
      "4499  w1:  [[0.26699355]\n",
      " [1.5759567 ]]\n",
      "4999  w1:  [[0.3167388]\n",
      " [1.540169 ]]\n",
      "5499  w1:  [[0.36257315]\n",
      " [1.505924  ]]\n",
      "5999  w1:  [[0.40501028]\n",
      " [1.473442  ]]\n",
      "6499  w1:  [[0.44442728]\n",
      " [1.4428011 ]]\n",
      "6999  w1:  [[0.48111606]\n",
      " [1.4139948 ]]\n",
      "7499  w1:  [[0.51531166]\n",
      " [1.3869735 ]]\n",
      "7999  w1:  [[0.54721105]\n",
      " [1.3616626 ]]\n",
      "8499  w1:  [[0.57698536]\n",
      " [1.3379755 ]]\n",
      "8999  w1:  [[0.6047865]\n",
      " [1.3158202]]\n",
      "9499  w1:  [[0.6307511]\n",
      " [1.2951062]]\n",
      "9999  w1:  [[0.6550045]\n",
      " [1.2757436]]\n",
      "10499  w1:  [[0.67766184]\n",
      " [1.2576469 ]]\n",
      "10999  w1:  [[0.6988289]\n",
      " [1.2407357]]\n",
      "11499  w1:  [[0.718605 ]\n",
      " [1.2249326]]\n",
      "11999  w1:  [[0.73708147]\n",
      " [1.2101657 ]]\n",
      "12499  w1:  [[0.75434405]\n",
      " [1.1963679 ]]\n",
      "12999  w1:  [[0.7704732]\n",
      " [1.1834762]]\n",
      "13499  w1:  [[0.78554326]\n",
      " [1.1714305 ]]\n",
      "13999  w1:  [[0.79962355]\n",
      " [1.1601753 ]]\n",
      "14499  w1:  [[0.81277937]\n",
      " [1.1496596 ]]\n",
      "14999  w1:  [[0.8250717]\n",
      " [1.1398332]]\n",
      "15499  w1:  [[0.8365563]\n",
      " [1.1306525]]\n",
      "15999  w1:  [[0.847288]\n",
      " [1.122074]]\n",
      "16499  w1:  [[0.85731417]\n",
      " [1.1140594 ]]\n",
      "16999  w1:  [[0.86668277]\n",
      " [1.1065707 ]]\n",
      "17499  w1:  [[0.8754358]\n",
      " [1.0995736]]\n",
      "17999  w1:  [[0.88361377]\n",
      " [1.093036  ]]\n",
      "18499  w1:  [[0.8912557]\n",
      " [1.0869285]]\n",
      "18999  w1:  [[0.89839554]\n",
      " [1.0812204 ]]\n",
      "19499  w1:  [[0.9050666]\n",
      " [1.0758878]]\n",
      "19999  w1:  [[0.91129947]\n",
      " [1.0709046 ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "BATCH_SIZE = 8\n",
    "SEED = 1\n",
    "\n",
    "rdm = np.random.RandomState(SEED)\n",
    "\n",
    "X = rdm.rand(32, 2)\n",
    "Y_ = [[x0+x1] for (x0, x1) in X]\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=(None, 2))\n",
    "y_ = tf.placeholder(tf.float32, shape=(None, 1))\n",
    "w1 = tf.Variable(tf.random_normal((2,1), stddev=1, seed=1))\n",
    "\n",
    "y = tf.matmul(x, w1)\n",
    "\n",
    "loss = tf.reduce_mean(tf.square(y-y_))\n",
    "train_step = tf.train.GradientDescentOptimizer(0.001).minimize(loss)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    init_op = tf.global_variables_initializer()\n",
    "    sess.run(init_op)\n",
    "    \n",
    "    STEPS = 20000\n",
    "    for i in range(STEPS):\n",
    "        start = i*BATCH_SIZE % 32\n",
    "        end = start+BATCH_SIZE\n",
    "        sess.run(train_step, feed_dict={x: X[start:end], y_: Y_[start:end]})\n",
    "        \n",
    "        if (i+1) % 500 == 0:\n",
    "            print(i, ' w1: ', sess.run(w1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
